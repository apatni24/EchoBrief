# üéß EchoBrief ‚Äî Scalable Podcast Summarization Backend

**EchoBrief** is a fast, event-driven backend system that transcribes and summarizes podcast episodes in real time. Users simply paste a podcast episode URL, choose a summary format (bullet points, narrative, or takeaways), and receive a high-quality summary within a minute for episodes up to 30 minutes.

> ‚è±Ô∏è **Summarizes a 30-minute podcast in <90 seconds**  
> üåç Deployed on low-latency infrastructure (Singapore ‚Äì Render + Upstash)

---

## üß† Why This Project Stands Out

This project demonstrates:

- ‚öôÔ∏è Real-world **event-driven microservice architecture**
- üåê Efficient **streaming workflows** using Redis Streams
- üß† Use of **LLMs (LLaMA 3.3 70B Versatile)** for high-quality summarization
- üîÅ **WebSocket-based updates** for live frontend interaction
- üê≥ Clean deployment with **Docker + NGINX reverse proxy**
- üöÄ Built-in **cold start mitigation** for smoother UX
- üì¶ Modular design across audio, transcription, and summarization layers

---

## üß© Architecture

![EchoBrief Architecture](./assets/architecture.svg)

*Note: Mermaid diagrams may not render correctly on all platforms; hence, a static image is provided.*

---

## üîÅ Cold Start Optimization

Render auto-suspends inactive services, which can cause a ~25‚Äì30s delay on the first request. To combat this:

> ‚ö° As soon as the frontend loads, it pings the backend's `/health` endpoint to **pre-warm** the server ‚Äî ensuring fast, seamless user experience even after idle periods.

---

## üì® Example Payload

Here‚Äôs a sample event payload passed to the Redis Stream (`audio_uploaded`) when a podcast is fetched:

```json
{
  "file_path": "",
  "metadata": {
    "summary": "",
    "show_title": "",
    "show_summary": ""
  },
  "summary_type": "",
  "job_id": ""
}
```
**Fields explained:**

- `file_path`: Local/remote audio path  
- `metadata`: Podcast title, episode summary, and show description  
- `summary_type`: Format (e.g., `ts` = story-style/takeaways)  
- `job_id`: Correlation ID for async WebSocket updates  

---

## üõ†Ô∏è Tech Stack

| Layer              | Tool / Service                           |
|--------------------|------------------------------------------|
| Audio Resolution   | Python + feedparser                      |
| Transcription      | AssemblyAI (diarization + speech-to-text)|
| Summarization      | LLaMA 3.3 70B Versatile (via API)        |
| Events             | Redis Streams (Upstash ‚Äì Singapore)      |
| Real-Time Updates  | WebSockets                               |
| Infrastructure     | Docker + NGINX + Render                  |
| Frontend           | Simple React App                         |

---

## üìÅ Project Structure

```plaintext
echobrief/
‚îú‚îÄ‚îÄ podcast_audio_resolver_service/    # RSS parsing, file download & event emit
‚îú‚îÄ‚îÄ transcription_service/             # Diarization + transcription via AssemblyAI
‚îú‚îÄ‚îÄ summarization_service/             # LLM-based summarization
‚îú‚îÄ‚îÄ redis_stream_client.py             # Redis Streams abstraction
‚îú‚îÄ‚îÄ nginx.conf                         # Reverse proxy config (internal routing)
‚îú‚îÄ‚îÄ Dockerfile                         # Container for all services
‚îú‚îÄ‚îÄ start.sh                           # Entrypoint to run everything
‚îî‚îÄ‚îÄ audio_files/                       # (Optional) Local audio storage
```

---

## üìÑ Summary Types Supported

- üîπ Bullet Points
- üìò Narrative (Story Format)
- üìå Key Takeaways

---

## üìâ API Rate Limiting

To comply with **ChatGroq API's per-minute token limit**, EchoBrief enforces:

> ‚è≥ **A 60-second cooldown between successive LLM summarization requests**

This ensures:

- No unexpected rate-limit errors during high load
- More predictable performance under concurrent usage
- Graceful queuing of summaries without affecting user experience

> The rate-limiting is implemented with an internal wait logic before calling the LLM API, keeping throughput compliant with usage constraints.

---


## üöÄ Getting Started (Local Dev)

```bash
# Clone the repo
git clone https://github.com/apatni24/EchoBrief.git
cd EchoBrief

# Build and run
docker build -t echobrief .
./start.sh
```

You‚Äôll have:

- All backend microservices up on internal ports
- NGINX reverse proxy managing internal routes
- Redis Streams wiring event flow between services

---

## üñºÔ∏è Frontend Screenshots

![EchoBrief Frontend - Input Screen](./assets/frontend_input.png)  
*User inputs podcast URL and selects summary type.*

![EchoBrief Frontend - Summary Output](./assets/frontend_output.png)  
*Generated summary is displayed live via WebSocket.*

---

## üë®‚Äçüíª Author

Built by [Atishay Patni](https://www.linkedin.com/in/atishaypatni)  
SDE @ Wells Fargo | Backend Engineer 

---

## üìå Future Enhancements

- GPU-based transcription (WhisperX + PyAnnote)
- Support for >30 min podcasts (chunking + parallel summary stitching)
- Authentication and saved summary history
- Podcast directory browsing from within the app

---
